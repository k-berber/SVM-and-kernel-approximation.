# SVM-and-kernel-approximation.
In the basic version of SVM, there is nothing special about it - we just use a special loss function that does not require indenting to infinity; The kernel SVM, unfortunately, is quite expensive in memory (you need to store a 𝑑 × 𝑑 Gram matrix) and in time. There are ways to calculate new features 𝜑̃ (𝑥) based on the original ones so that the scalar products of these new ⟨𝜑̃ (𝑥), 𝜑̃ (𝑧)⟩ approximate the kernel 𝐾 (𝑥, 𝑧).  We will investigate approximations by the Random Fourier Features (RFF) method for Gaussian kernels.  We will build any linear model based on the new features 𝜑̃ (𝑥).
