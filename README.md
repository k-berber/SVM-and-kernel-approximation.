# SVM-and-kernel-approximation.
In the basic version of SVM, there is nothing special about it - we just use a special loss function that does not require indenting to infinity; The kernel SVM, unfortunately, is quite expensive in memory (you need to store a ğ‘‘ Ã— ğ‘‘ Gram matrix) and in time. There are ways to calculate new features ğœ‘Ìƒ (ğ‘¥) based on the original ones so that the scalar products of these new âŸ¨ğœ‘Ìƒ (ğ‘¥), ğœ‘Ìƒ (ğ‘§)âŸ© approximate the kernel ğ¾ (ğ‘¥, ğ‘§).  We will investigate approximations by the Random Fourier Features (RFF) method for Gaussian kernels.  We will build any linear model based on the new features ğœ‘Ìƒ (ğ‘¥).
